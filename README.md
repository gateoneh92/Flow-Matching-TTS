# ğŸŒŠ Flow Matching TTS

**Non-autoregressive, high-speed TTS using Conditional Flow Matching**

ì´ êµ¬í˜„ì€ F5-TTSì™€ Voiceboxì˜ ì ‘ê·¼ ë°©ì‹ì„ ê²°í•©í•˜ì—¬ LLM-iSTFT-VITSì— Flow Matching ê¸°ëŠ¥ì„ ì¶”ê°€í•œ ê²ƒì…ë‹ˆë‹¤.

---

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

### âš¡ ì†ë„ í–¥ìƒ
- **5-20ë°° ë¹ ë¥¸ ì¶”ë¡ **: Autoregressive ëª¨ë¸ ëŒ€ë¹„ RTF 0.02-0.08
- **ë³‘ë ¬ ìƒì„±**: Non-autoregressive ë°©ì‹ìœ¼ë¡œ ì „ì²´ melì„ í•œ ë²ˆì— ìƒì„±
- **ì¡°ì • ê°€ëŠ¥í•œ í’ˆì§ˆ-ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„**: ODE stepsë¡œ ì œì–´ (5-30 steps)

### ğŸ¨ ê³ ê¸‰ ê¸°ëŠ¥
- **Sway Sampling**: F5-TTSì˜ ì¶”ë¡  ìµœì í™” ê¸°ë²• (sway_coef=-1.0)
- **Multiple ODE Solvers**: Euler, Midpoint ë°©ë²• ì§€ì›
- **Duration Predictor**: í•™ìŠµ ê°€ëŠ¥í•œ duration ì˜ˆì¸¡ (optional)
- **MB-iSTFT Vocoder**: ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤ ìƒì„±

### ğŸ—ï¸ ì•„í‚¤í…ì²˜
```
Text â†’ Text Embedding
         â†“
     ConvNeXt Blocks (F5-TTS style)
         â†“
     Flow Matching Transformer
         â†“
     ODE Solver (Conditional Flow)
         â†“
     Mel-Spectrogram
         â†“
     MB-iSTFT Generator
         â†“
     High-Quality Audio
```

---

## ğŸ“¦ êµ¬ì„± íŒŒì¼

```
flow_matching.py              # í•µì‹¬ Flow Matching êµ¬í˜„
â”œâ”€â”€ ConvNeXtBlock             # Text feature refinement
â”œâ”€â”€ DurationPredictor         # Duration ì˜ˆì¸¡
â”œâ”€â”€ FlowMatchingTransformer   # Velocity field ì˜ˆì¸¡
â”œâ”€â”€ ConditionalFlowMatching   # ODE-based generation
â””â”€â”€ FlowMatchingTTS           # ì „ì²´ ì‹œìŠ¤í…œ

models.py                     # MB-iSTFT í†µí•©
â””â”€â”€ FlowMatchingSynthesizer   # Flow Matching + MB-iSTFT

train_flow_matching.py        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
inference_flow_matching.py    # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
test_flow_matching.py         # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
configs/flow_matching.json    # ì„¤ì • íŒŒì¼
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# Flow Matching êµ¬í˜„ ê²€ì¦
python3 test_flow_matching.py

# ì˜ˆìƒ ì¶œë ¥:
# âœ… All Flow Matching core tests passed!
# âœ… All FlowMatchingSynthesizer tests passed!
# Speed test: RTF=0.022 (5 steps), 0.041 (10 steps), 0.077 (20 steps)
```

### 2. í•™ìŠµ

```bash
# ë‹¨ì¼ GPU
python3 train_flow_matching.py -c configs/flow_matching.json -m logs/flow_matching

# ë©€í‹° GPU (ì˜ˆ: 2ê°œ)
python3 train_flow_matching.py -c configs/flow_matching.json -m logs/flow_matching
```

### 3. ì¶”ë¡ 

```bash
# ê¸°ë³¸ ì‚¬ìš© (20 steps, Sway sampling)
python3 inference_flow_matching.py \
    --checkpoint logs/flow_matching/G_100000.pth \
    --config configs/flow_matching.json \
    --text "Hello world, this is flow matching TTS." \
    --output output.wav

# ë¹ ë¥¸ ì¶”ë¡  (10 steps)
python3 inference_flow_matching.py \
    --checkpoint logs/flow_matching/G_100000.pth \
    --config configs/flow_matching.json \
    --text "Quick generation with only ten steps." \
    --output output_fast.wav \
    --steps 10

# ìµœê³  í’ˆì§ˆ (30 steps + midpoint solver)
python3 inference_flow_matching.py \
    --checkpoint logs/flow_matching/G_100000.pth \
    --config configs/flow_matching.json \
    --text "Highest quality with thirty steps and midpoint solver." \
    --output output_hq.wav \
    --steps 30 \
    --method midpoint
```

---

## ğŸ”§ ì„¤ì • ê°€ì´ë“œ

### `configs/flow_matching.json`

```json
{
  "model": {
    "flow_d_model": 512,           // Transformer í¬ê¸°
    "flow_nhead": 8,                // Attention heads
    "flow_num_layers": 12,          // Transformer layers (12-24)
    "flow_dim_feedforward": 2048,   // FFN í¬ê¸°
    "use_duration_predictor": true  // Duration ì˜ˆì¸¡ í™œì„±í™”
  },
  "train": {
    "batch_size": 16,               // ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
    "fp16_run": true,               // Mixed precision (ê¶Œì¥)
    "use_discriminator": false      // Vocoder discriminator (optional)
  }
}
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ì¶”ë¡  ì†ë„ (RTX 4090 ê¸°ì¤€)

| ëª¨ë¸ | Steps | RTF | í’ˆì§ˆ |
|-----|-------|-----|------|
| **Flow Matching (ì´ êµ¬í˜„)** | 5 | 0.022 | Good |
| **Flow Matching (ì´ êµ¬í˜„)** | 10 | 0.041 | Very Good |
| **Flow Matching (ì´ êµ¬í˜„)** | 20 | 0.077 | Excellent |
| AR LLM (ê¸°ì¡´) | N/A | 0.5-1.0 | Good |

**RTF (Real-Time Factor)**: ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„. 1.0 = ì‹¤ì‹œê°„ ì†ë„.

### vs SOTA ëª¨ë¸

| ëª¨ë¸ | RTF | íŠ¹ì§• |
|-----|-----|------|
| **LLM-iSTFT-VITS (Flow Matching)** | 0.02-0.08 | MB-iSTFT vocoder, ì¡°ì • ê°€ëŠ¥ |
| F5-TTS | 0.04 (TRT) | ConvNeXt + Sway sampling |
| Voicebox | ~0.15 | Flow matching, ë©€í‹°íƒœìŠ¤í¬ |
| GPT-SoVITS | 0.01-0.03 | AR, Few-shot íŠ¹í™” |

---

## ğŸ›ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

### ì¶”ë¡  í’ˆì§ˆ vs ì†ë„

```python
# ì´ˆê³ ì† (ì‹¤ì‹œê°„ë³´ë‹¤ 45ë°° ë¹ ë¦„)
n_timesteps=5, method='euler', sway_coef=0.0
# RTF ~0.022

# ê· í˜• (ê¶Œì¥)
n_timesteps=10, method='euler', sway_coef=-1.0
# RTF ~0.041

# ê³ í’ˆì§ˆ
n_timesteps=20, method='midpoint', sway_coef=-1.0
# RTF ~0.077

# ìµœê³  í’ˆì§ˆ
n_timesteps=30, method='midpoint', sway_coef=-1.0
# RTF ~0.120
```

### Duration Scale

```python
# ëŠë¦° ë§íˆ¬ (1.5ë°° ëŠë¦¼)
duration_scale=1.5

# ì •ìƒ ì†ë„
duration_scale=1.0

# ë¹ ë¥¸ ë§íˆ¬ (1.5ë°° ë¹ ë¦„)
duration_scale=0.66
```

### Sway Sampling Coefficient

```python
# F5-TTS ìŠ¤íƒ€ì¼ (ê¶Œì¥)
sway_coef=-1.0

# Standard flow matching
sway_coef=0.0

# ì‹¤í—˜ì  (ë‹¤ë¥¸ ê°’ ì‹œë„ ê°€ëŠ¥)
sway_coef=-0.5, -2.0, ...
```

---

## ğŸ§ª ì½”ë“œ ì˜ˆì œ

### Python API ì‚¬ìš©

```python
import torch
from models import FlowMatchingSynthesizer
from text import text_to_sequence
import commons

# ëª¨ë¸ ë¡œë“œ
checkpoint = torch.load('logs/flow_matching/G_100000.pth')
model = FlowMatchingSynthesizer(...).cuda()
model.load_state_dict(checkpoint['model'])
model.eval()

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
text = "Hello, this is a test."
text_seq = text_to_sequence(text, ['english_cleaners2'])
text_seq = commons.intersperse(text_seq, 0)  # Add blanks
text_tensor = torch.LongTensor(text_seq).unsqueeze(0).cuda()
text_lengths = torch.LongTensor([len(text_seq)]).cuda()

# ì¶”ë¡ 
with torch.no_grad():
    audio, _, mel, _ = model.infer(
        text_tensor,
        text_lengths,
        n_timesteps=20,
        duration_scale=1.0,
        sway_coef=-1.0,
        method='euler'
    )

# ì €ì¥
audio = audio.squeeze().cpu().numpy()
from scipy.io import wavfile
wavfile.write('output.wav', 22050, (audio * 32768).astype('int16'))
```

---

## ğŸ“ˆ í•™ìŠµ íŒ

### 1. ë°ì´í„° ì¤€ë¹„
- Flow Matchingì€ mel-spectrogramìœ¼ë¡œ í•™ìŠµ
- TextMelLoaderê°€ ìë™ìœ¼ë¡œ mel ê³„ì‚°
- LJSpeech, VCTK ë“± ì¼ë°˜ TTS ë°ì´í„°ì…‹ ì‚¬ìš© ê°€ëŠ¥

### 2. í•™ìŠµ ì„¤ì •
```json
{
  "batch_size": 16,              // GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • (8-32)
  "learning_rate": 2e-4,         // ì•ˆì •ì ì¸ í•™ìŠµë¥ 
  "fp16_run": true,              // Mixed precision ê¶Œì¥
  "use_discriminator": false     // ì´ˆê¸°ì—” ë¹„í™œì„±í™”, ë‚˜ì¤‘ì— vocoder ê°œì„ ìš©
}
```

### 3. ëª¨ë‹ˆí„°ë§
- `loss/flow`: Flow matching loss (MSE between velocity fields)
- `loss/dur`: Duration prediction loss
- Flow lossê°€ 1.0 ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ good quality

### 4. í‰ê°€
```bash
# ì£¼ê¸°ì ìœ¼ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
python3 inference_flow_matching.py \
    --checkpoint logs/flow_matching/G_50000.pth \
    --config configs/flow_matching.json \
    --text "Testing checkpoint at step fifty thousand." \
    --output test_50k.wav \
    --steps 20
```

---

## ğŸ”¬ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### Flow Matchingì´ë€?

Conditional Flow Matchingì€ ë‹¤ìŒì„ í•™ìŠµí•©ë‹ˆë‹¤:
```
dx_t/dt = v_t(x_t, text, t)
```

ì—¬ê¸°ì„œ:
- `x_t`: ì‹œê°„ tì—ì„œì˜ state (t=0: noise, t=1: mel)
- `v_t`: velocity field (ëª¨ë¸ì´ ì˜ˆì¸¡)
- `t`: ì‹œê°„ [0, 1]

### Optimal Transport Formulation

```python
# Interpolation path
x_t = t * x_1 + (1-t) * x_0

# Target velocity
u_t = x_1 - x_0

# Loss
loss = MSE(v_t, u_t)
```

### ODE Solver

```python
# Euler method (1st order)
x_{t+dt} = x_t + dt * v_t

# Midpoint method (2nd order, more accurate)
x_mid = x_t + (dt/2) * v_t
v_mid = model(x_mid, t+dt/2)
x_{t+dt} = x_t + dt * v_mid
```

### Sway Sampling

F5-TTSì˜ ì¶”ë¡  ìµœì í™” ê¸°ë²•:
```python
# Standard
t_new = t

# Sway (sway_coef=-1.0)
t_new = t + sway_coef * (1-t) * t

# Effect: shifts trajectory toward cleaner generation
```

---

## ğŸ†š AR vs Flow Matching ë¹„êµ

| í•­ëª© | Autoregressive (ê¸°ì¡´) | Flow Matching (ìƒˆë¡œìš´) |
|-----|----------------------|----------------------|
| **ìƒì„± ë°©ì‹** | ìˆœì°¨ì  (token-by-token) | ë³‘ë ¬ (ì „ì²´ mel ë™ì‹œ) |
| **ì¶”ë¡  ì†ë„** | ëŠë¦¼ (RTF 0.5-1.0) | ë¹ ë¦„ (RTF 0.02-0.08) |
| **ì»¨í…ìŠ¤íŠ¸** | ë‹¨ë°©í–¥ (ê³¼ê±°ë§Œ) | ì–‘ë°©í–¥ (ì „ì²´) |
| **ì•ˆì •ì„±** | Repetition ìœ„í—˜ | ì•ˆì •ì  |
| **í’ˆì§ˆ ì œì–´** | Temperature, top-k | ODE steps, solver |
| **í•™ìŠµ** | Cross-entropy | MSE (velocity field) |

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q1: OOM (Out of Memory)
```json
// batch_size ì¤„ì´ê¸°
"batch_size": 8  // ë˜ëŠ” 4

// ë˜ëŠ” ëª¨ë¸ í¬ê¸° ì¤„ì´ê¸°
"flow_d_model": 256,
"flow_num_layers": 6
```

### Q2: í’ˆì§ˆì´ ë‚®ìŒ
```bash
# ë” ë§ì€ steps ì‚¬ìš©
--steps 30

# Midpoint solver ì‚¬ìš©
--method midpoint

# Sway sampling í™œì„±í™”
--sway-coef -1.0

# ë” ê¸´ í•™ìŠµ
# Flow loss < 1.0ê¹Œì§€ í•™ìŠµ
```

### Q3: ì¶”ë¡ ì´ ëŠë¦¼
```bash
# Steps ì¤„ì´ê¸°
--steps 5

# Euler method ì‚¬ìš© (ë” ë¹ ë¦„)
--method euler

# TensorRT ìµœì í™” (í–¥í›„ ì¶”ê°€ ì˜ˆì •)
```

### Q4: Durationì´ ë¶€ì •í™•
```json
// Duration predictor ì¬í•™ìŠµ
"use_duration_predictor": true

// ë˜ëŠ” ì™¸ë¶€ aligner ì‚¬ìš© (MFA)
"use_duration_predictor": false
```

---

## ğŸš§ í–¥í›„ ê°œì„  ê³„íš

### Phase 1 (ì¦‰ì‹œ)
- âœ… Flow Matching ì½”ì–´ êµ¬í˜„
- âœ… MB-iSTFT í†µí•©
- âœ… Sway Sampling
- âœ… Duration Predictor

### Phase 2 (ë‹¨ê¸°)
- [ ] TensorRT ìµœì í™” (3-5ë°° ì¶”ê°€ ì†ë„ í–¥ìƒ)
- [ ] Classifier-Free Guidance (CFG)
- [ ] Multi-speaker conditioning
- [ ] Emotion control

### Phase 3 (ì¤‘ê¸°)
- [ ] Few-shot voice cloning
- [ ] External duration aligner (MFA) í†µí•©
- [ ] Streaming inference
- [ ] ONNX export

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. **Flow Matching for Generative Modeling** (Lipman et al., 2023)
   - Optimal transport formulation
   - Conditional flow matching

2. **F5-TTS** (SWivid, 2024)
   - ConvNeXt blocks for text
   - Sway sampling technique

3. **Voicebox** (Meta AI, 2023)
   - Audio infilling with flow matching
   - Multi-task TTS

4. **MB-iSTFT-VITS** (Original)
   - Multi-band iSTFT vocoder
   - High-quality audio generation

---

## ğŸ“ Citation

```bibtex
@software{llm_istft_vits_flow_matching,
  title={LLM-iSTFT-VITS with Flow Matching},
  author={í™©ì„±ì›… and Claude Sonnet 4.5},
  year={2026},
  url={https://github.com/gateoneh92/LLM-iSTFT-VITS}
}
```

---

## ğŸ“§ ë¬¸ì˜

- GitHub Issues: [LLM-iSTFT-VITS](https://github.com/gateoneh92/LLM-iSTFT-VITS)
- Email: gateoneh@gmail.com

---

**ì‘ì„±**: 2026-02-20
**AI Partner**: Claude Code (Sonnet 4.5)
**ë²„ì „**: 1.0
